{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1NmNt_wipFGsXSEZCjim1IIeg9tO0Mfj2",
      "authorship_tag": "ABX9TyOJ4pU46kZNfKRaUGDQziJO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nilsonmax/30-Days-Of-Python/blob/master/train_CNN_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python predict.py --image ../../datasets/images/986e6f36-ddd3-41d6-b9a0-15ba6adfc284.jpg --caption \"Enviar al domicilio\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eb7a2bc-3ac4-41c0-dc11-805ad2cf29ab",
        "id": "bYQ-IMnTA_tb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/models/multimodal/cnn_lstm/predict.py\", line 31, in <module>\n",
            "    model.load_state_dict(checkpoint)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2041, in load_state_dict\n",
            "    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n",
            "RuntimeError: Error(s) in loading state_dict for LateFusion:\n",
            "\tsize mismatch for encoders.text.embedding.weight: copying a param with shape torch.Size([30522, 20]) from checkpoint, the shape in current model is torch.Size([1000, 20]).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python predict.py --image ../../datasets/images/986e6f36-ddd3-41d6-b9a0-15ba6adfc284.jpg --caption \"Enviar al domicilio\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a771a201-fee8-4ba2-e2c3-c9f29397b65e",
        "id": "BsAzV4OtBBJA"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: Bold Text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1yXE8W8Ytml1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff9d4498-4072-4d7a-88b3-8e79fc6cede3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  models.zip\n",
            "  inflating: models/.DS_Store        \n",
            "   creating: models/datasets/\n",
            "  inflating: models/datasets/.DS_Store  \n",
            "  inflating: models/datasets/cnn_lstm.csv  \n",
            "  inflating: models/datasets/cnn_lstm_classes.json  \n",
            "   creating: models/datasets/images/\n",
            "  inflating: models/datasets/images/0163a59e-6d30-405e-89c6-b64ddb581792.jpg  \n",
            "  inflating: models/datasets/images/083d30d2-ccaf-44c6-bd46-fee99a603830.jpg  \n",
            "  inflating: models/datasets/images/09fb8f15-15bb-494d-aa3c-6ba82e013744.jpg  \n",
            "  inflating: models/datasets/images/0c5d0100-c8fd-408e-b811-785f58fea014.jpg  \n",
            "  inflating: models/datasets/images/0c8023aa-1c00-4e93-bcc9-0aa6b1f7b766.png  \n",
            " extracting: models/datasets/images/13d079ae-be5c-49a3-bf99-39a259514968.png  \n",
            " extracting: models/datasets/images/14742b34-f613-4bf8-b0d7-c163866c6d5d.png  \n",
            " extracting: models/datasets/images/288a81f4-a558-4770-b233-2413c87f8beb.png  \n",
            "  inflating: models/datasets/images/2b622862-fc80-4b2d-9aad-d46b3a751b38.jpg  \n",
            " extracting: models/datasets/images/2b83a2fc-8f35-45c7-9c5b-729a5f5db4b2.jpg  \n",
            "  inflating: models/datasets/images/3b71d600-9723-4b3d-890f-319cc278ba10.png  \n",
            "  inflating: models/datasets/images/3c3bb070-fdff-4c26-b3de-85597d607020.jpg  \n",
            "  inflating: models/datasets/images/41f236a0-ef61-4dc2-8a12-4d8557761486.jpg  \n",
            " extracting: models/datasets/images/496e73af-3fd3-444c-a4e7-9b3c87789315.jpg  \n",
            " extracting: models/datasets/images/510f7373-0262-4783-8a39-02b8f9e4a997.png  \n",
            " extracting: models/datasets/images/52230c8d-5685-47d2-af51-f497eab2ca1a.png  \n",
            " extracting: models/datasets/images/6ab95e15-6615-4d90-b3e2-3dd01552394d.jpg  \n",
            " extracting: models/datasets/images/6aef7f77-02e9-4c90-8048-fb7f3f8a4575.png  \n",
            " extracting: models/datasets/images/79b0dc24-d77d-4b4a-98c6-65499b7f4cc4.png  \n",
            "  inflating: models/datasets/images/7dac1b22-37cb-4078-ad90-0924076afbf6.png  \n",
            "  inflating: models/datasets/images/8020ae2e-d0d6-40f5-9994-129613745cd7.jpg  \n",
            " extracting: models/datasets/images/825734e5-50f2-431f-956d-c1f78aad4efd.jpg  \n",
            "  inflating: models/datasets/images/8305273f-9fc6-45c1-946b-a57ed39f5bbe.jpg  \n",
            " extracting: models/datasets/images/986e6f36-ddd3-41d6-b9a0-15ba6adfc284.jpg  \n",
            " extracting: models/datasets/images/99ccb483-8a64-46c6-809e-9d52ece456c6.png  \n",
            "  inflating: models/datasets/images/a0e75bed-fc65-4f1c-971c-3c7efbecdf63.jpg  \n",
            "  inflating: models/datasets/images/a58f9d43-8560-40f4-8478-a0074a457537.jpg  \n",
            " extracting: models/datasets/images/a72143c3-1acd-4955-b82b-42693891cc9a.jpg  \n",
            "  inflating: models/datasets/images/a86558e5-b85b-4f48-a5d3-ebd2787cc61b.jpg  \n",
            " extracting: models/datasets/images/adc87f7a-4b2c-4455-b407-10f588436f3d.jpg  \n",
            "  inflating: models/datasets/images/b60f5fdf-5076-420d-80f2-388ef24e8b6f.jpg  \n",
            " extracting: models/datasets/images/be078387-4d8e-4297-898c-5179bc0c5fa9.jpg  \n",
            " extracting: models/datasets/images/cf1296a5-fdd5-4249-b532-48ae6e7227b6.jpg  \n",
            "  inflating: models/datasets/images/d0b6867c-5060-4bdc-9e14-087dddc56dc1.jpg  \n",
            "  inflating: models/datasets/images/d3426673-45ce-4e74-a200-c6cc343c9551.jpg  \n",
            "  inflating: models/datasets/images/d4758416-6703-4835-ba6b-8cbf33fa3474.png  \n",
            " extracting: models/datasets/images/d8476be7-a328-44fb-811a-d249a1f678cb.jpg  \n",
            " extracting: models/datasets/images/d93e8353-ebad-4334-a15b-8e682b960634.png  \n",
            "  inflating: models/datasets/images/e01e345a-dcfd-4b58-8a8b-319f3046fcdc.png  \n",
            " extracting: models/datasets/images/edcb11eb-102f-4ef7-9c10-4fc69e542ce7.png  \n",
            " extracting: models/datasets/images/f3189808-67c4-42d8-ae74-276f71d780e7.jpg  \n",
            "  inflating: models/datasets/images/f6d13034-bd69-4b7d-97bf-8b64a798f766.jpg  \n",
            "   creating: models/multimodal/\n",
            "  inflating: models/multimodal/.DS_Store  \n",
            "   creating: models/multimodal/cnn_lstm/\n",
            "   creating: models/multimodal/cnn_lstm/__pycache__/\n",
            "  inflating: models/multimodal/cnn_lstm/__pycache__/cnn_encoder.cpython-310.pyc  \n",
            "  inflating: models/multimodal/cnn_lstm/__pycache__/cnn_lstm.cpython-310.pyc  \n",
            "  inflating: models/multimodal/cnn_lstm/__pycache__/lstm_encoder.cpython-310.pyc  \n",
            "  inflating: models/multimodal/cnn_lstm/__pycache__/utils.cpython-310.pyc  \n",
            "  inflating: models/multimodal/cnn_lstm/cnn_encoder.py  \n",
            "  inflating: models/multimodal/cnn_lstm/cnn_lstm.py  \n",
            "  inflating: models/multimodal/cnn_lstm/lstm_encoder.py  \n",
            "  inflating: models/multimodal/cnn_lstm/model.pth  \n",
            "  inflating: models/multimodal/cnn_lstm/predict.py  \n",
            "  inflating: models/multimodal/cnn_lstm/readme.md  \n",
            " extracting: models/multimodal/cnn_lstm/requirements.txt  \n",
            "   creating: models/multimodal/cnn_lstm/tests/\n",
            "  inflating: models/multimodal/cnn_lstm/tests/test_cnn_encoder.py  \n",
            "  inflating: models/multimodal/cnn_lstm/tests/test_cnn_lstm.py  \n",
            "  inflating: models/multimodal/cnn_lstm/tests/test_lstm_encoder.py  \n",
            "  inflating: models/multimodal/cnn_lstm/train.py  \n",
            "  inflating: models/multimodal/cnn_lstm/utils.py  \n"
          ]
        }
      ],
      "source": [
        "!unzip models.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BCEN_crvYTx",
        "outputId": "be3e131f-2ec0-4c45-f5ff-dbfae3f01bc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models\tmodels.zip  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd models/multimodal/cnn_lstm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFCbQbYmvoqU",
        "outputId": "4920650b-386e-4f72-e9d6-45c498e62fd0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/multimodal/cnn_lstm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7bk0drtxMv_",
        "outputId": "c2ff52ee-0ec2-4c52-a176-abeb934d068d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmultimodal-nightly (from -r requirements.txt (line 1))\n",
            "  Downloading torchmultimodal_nightly-2023.7.15-py39-none-any.whl (160 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/160.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.8/160.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.15.2)\n",
            "Collecting DALL-E==0.1 (from torchmultimodal-nightly->-r requirements.txt (line 1))\n",
            "  Downloading DALL_E-0.1-py3-none-any.whl (6.0 kB)\n",
            "Collecting iopath (from torchmultimodal-nightly->-r requirements.txt (line 1))\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs==23.1.0 in /usr/local/lib/python3.10/dist-packages (from torchmultimodal-nightly->-r requirements.txt (line 1)) (23.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from DALL-E==0.1->torchmultimodal-nightly->-r requirements.txt (line 1)) (8.4.0)\n",
            "Collecting blobfile (from DALL-E==0.1->torchmultimodal-nightly->-r requirements.txt (line 1))\n",
            "  Downloading blobfile-2.0.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mypy (from DALL-E==0.1->torchmultimodal-nightly->-r requirements.txt (line 1))\n",
            "  Downloading mypy-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from DALL-E==0.1->torchmultimodal-nightly->-r requirements.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from DALL-E==0.1->torchmultimodal-nightly->-r requirements.txt (line 1)) (7.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from DALL-E==0.1->torchmultimodal-nightly->-r requirements.txt (line 1)) (2.27.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from DALL-E==0.1->torchmultimodal-nightly->-r requirements.txt (line 1)) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from DALL-E==0.1->torchmultimodal-nightly->-r requirements.txt (line 1)) (0.15.2+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext->-r requirements.txt (line 2)) (4.65.0)\n",
            "Requirement already satisfied: torchdata==0.6.1 in /usr/local/lib/python3.10/dist-packages (from torchtext->-r requirements.txt (line 2)) (0.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->DALL-E==0.1->torchmultimodal-nightly->-r requirements.txt (line 1)) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->DALL-E==0.1->torchmultimodal-nightly->-r requirements.txt (line 1)) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->DALL-E==0.1->torchmultimodal-nightly->-r requirements.txt (line 1)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->DALL-E==0.1->torchmultimodal-nightly->-r requirements.txt (line 1)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->DALL-E==0.1->torchmultimodal-nightly->-r requirements.txt (line 1)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->DALL-E==0.1->torchmultimodal-nightly->-r requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.1->torchtext->-r requirements.txt (line 2)) (1.26.16)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->DALL-E==0.1->torchmultimodal-nightly->-r requirements.txt (line 1)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->DALL-E==0.1->torchmultimodal-nightly->-r requirements.txt (line 1)) (16.0.6)\n",
            "Collecting portalocker (from iopath->torchmultimodal-nightly->-r requirements.txt (line 1))\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->DALL-E==0.1->torchmultimodal-nightly->-r requirements.txt (line 1)) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->DALL-E==0.1->torchmultimodal-nightly->-r requirements.txt (line 1)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->DALL-E==0.1->torchmultimodal-nightly->-r requirements.txt (line 1)) (3.4)\n",
            "Collecting pycryptodomex~=3.8 (from blobfile->DALL-E==0.1->torchmultimodal-nightly->-r requirements.txt (line 1))\n",
            "  Downloading pycryptodomex-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml~=4.9 in /usr/local/lib/python3.10/dist-packages (from blobfile->DALL-E==0.1->torchmultimodal-nightly->-r requirements.txt (line 1)) (4.9.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->DALL-E==0.1->torchmultimodal-nightly->-r requirements.txt (line 1)) (2.1.3)\n",
            "Collecting mypy-extensions>=1.0.0 (from mypy->DALL-E==0.1->torchmultimodal-nightly->-r requirements.txt (line 1))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from mypy->DALL-E==0.1->torchmultimodal-nightly->-r requirements.txt (line 1)) (2.0.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->DALL-E==0.1->torchmultimodal-nightly->-r requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->DALL-E==0.1->torchmultimodal-nightly->-r requirements.txt (line 1)) (23.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->DALL-E==0.1->torchmultimodal-nightly->-r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->DALL-E==0.1->torchmultimodal-nightly->-r requirements.txt (line 1)) (1.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->DALL-E==0.1->torchmultimodal-nightly->-r requirements.txt (line 1)) (1.3.0)\n",
            "Building wheels for collected packages: iopath\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31531 sha256=cc79d93ed996c534998dee5413bc533408f1be2aa0366b850207fcff1a1d4c9c\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
            "Successfully built iopath\n",
            "Installing collected packages: pycryptodomex, portalocker, mypy-extensions, mypy, iopath, blobfile, DALL-E, torchmultimodal-nightly\n",
            "Successfully installed DALL-E-0.1 blobfile-2.0.2 iopath-0.1.10 mypy-1.4.1 mypy-extensions-1.0.0 portalocker-2.7.0 pycryptodomex-3.18.0 torchmultimodal-nightly-2023.7.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/models/multimodal/cnn_lstm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEac9hM3TatD",
        "outputId": "6a172614-65e9-4c71-8b72-bc4c5d21f25d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/models/multimodal/cnn_lstm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yXLghHgv1gH",
        "outputId": "2d85d0af-90d6-42af-f257-21b92fcb877f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/128], Step [1/3], Loss: 3.1767\n",
            "Epoch [1/128], Step [2/3], Loss: 3.0987\n",
            "Epoch [1/128], Step [3/3], Loss: 2.9410\n",
            "Epoch [2/128], Step [1/3], Loss: 2.6457\n",
            "Epoch [2/128], Step [2/3], Loss: 2.6699\n",
            "Epoch [2/128], Step [3/3], Loss: 2.4908\n",
            "Epoch [3/128], Step [1/3], Loss: 2.3392\n",
            "Epoch [3/128], Step [2/3], Loss: 2.3948\n",
            "Epoch [3/128], Step [3/3], Loss: 2.3220\n",
            "Epoch [4/128], Step [1/3], Loss: 2.2114\n",
            "Epoch [4/128], Step [2/3], Loss: 2.0931\n",
            "Epoch [4/128], Step [3/3], Loss: 2.0446\n",
            "Epoch [5/128], Step [1/3], Loss: 1.6619\n",
            "Epoch [5/128], Step [2/3], Loss: 2.0912\n",
            "Epoch [5/128], Step [3/3], Loss: 1.8011\n",
            "Epoch [6/128], Step [1/3], Loss: 1.5142\n",
            "Epoch [6/128], Step [2/3], Loss: 1.8134\n",
            "Epoch [6/128], Step [3/3], Loss: 1.5622\n",
            "Epoch [7/128], Step [1/3], Loss: 1.3384\n",
            "Epoch [7/128], Step [2/3], Loss: 1.5826\n",
            "Epoch [7/128], Step [3/3], Loss: 1.4193\n",
            "Epoch [8/128], Step [1/3], Loss: 1.3381\n",
            "Epoch [8/128], Step [2/3], Loss: 1.1936\n",
            "Epoch [8/128], Step [3/3], Loss: 1.3342\n",
            "Epoch [9/128], Step [1/3], Loss: 1.1331\n",
            "Epoch [9/128], Step [2/3], Loss: 1.0641\n",
            "Epoch [9/128], Step [3/3], Loss: 1.0715\n",
            "Epoch [10/128], Step [1/3], Loss: 1.0032\n",
            "Epoch [10/128], Step [2/3], Loss: 1.2086\n",
            "Epoch [10/128], Step [3/3], Loss: 0.7956\n",
            "Epoch [11/128], Step [1/3], Loss: 0.8362\n",
            "Epoch [11/128], Step [2/3], Loss: 0.8261\n",
            "Epoch [11/128], Step [3/3], Loss: 0.9752\n",
            "Epoch [12/128], Step [1/3], Loss: 0.6935\n",
            "Epoch [12/128], Step [2/3], Loss: 0.7067\n",
            "Epoch [12/128], Step [3/3], Loss: 0.9233\n",
            "Epoch [13/128], Step [1/3], Loss: 0.7120\n",
            "Epoch [13/128], Step [2/3], Loss: 0.6707\n",
            "Epoch [13/128], Step [3/3], Loss: 0.6147\n",
            "Epoch [14/128], Step [1/3], Loss: 0.5823\n",
            "Epoch [14/128], Step [2/3], Loss: 0.4688\n",
            "Epoch [14/128], Step [3/3], Loss: 0.7386\n",
            "Epoch [15/128], Step [1/3], Loss: 0.5656\n",
            "Epoch [15/128], Step [2/3], Loss: 0.5973\n",
            "Epoch [15/128], Step [3/3], Loss: 0.4381\n",
            "Epoch [16/128], Step [1/3], Loss: 0.4243\n",
            "Epoch [16/128], Step [2/3], Loss: 0.4425\n",
            "Epoch [16/128], Step [3/3], Loss: 0.2617\n",
            "Epoch [17/128], Step [1/3], Loss: 0.3203\n",
            "Epoch [17/128], Step [2/3], Loss: 0.3797\n",
            "Epoch [17/128], Step [3/3], Loss: 0.4580\n",
            "Epoch [18/128], Step [1/3], Loss: 0.2881\n",
            "Epoch [18/128], Step [2/3], Loss: 0.3554\n",
            "Epoch [18/128], Step [3/3], Loss: 0.2519\n",
            "Epoch [19/128], Step [1/3], Loss: 0.2696\n",
            "Epoch [19/128], Step [2/3], Loss: 0.2073\n",
            "Epoch [19/128], Step [3/3], Loss: 0.8866\n",
            "Epoch [20/128], Step [1/3], Loss: 0.2696\n",
            "Epoch [20/128], Step [2/3], Loss: 0.3285\n",
            "Epoch [20/128], Step [3/3], Loss: 0.3822\n",
            "Epoch [21/128], Step [1/3], Loss: 0.2535\n",
            "Epoch [21/128], Step [2/3], Loss: 0.3241\n",
            "Epoch [21/128], Step [3/3], Loss: 0.2588\n",
            "Epoch [22/128], Step [1/3], Loss: 0.2780\n",
            "Epoch [22/128], Step [2/3], Loss: 0.2299\n",
            "Epoch [22/128], Step [3/3], Loss: 0.1891\n",
            "Epoch [23/128], Step [1/3], Loss: 0.2711\n",
            "Epoch [23/128], Step [2/3], Loss: 0.1577\n",
            "Epoch [23/128], Step [3/3], Loss: 0.1534\n",
            "Epoch [24/128], Step [1/3], Loss: 0.1382\n",
            "Epoch [24/128], Step [2/3], Loss: 0.1471\n",
            "Epoch [24/128], Step [3/3], Loss: 0.2079\n",
            "Epoch [25/128], Step [1/3], Loss: 0.1743\n",
            "Epoch [25/128], Step [2/3], Loss: 0.1181\n",
            "Epoch [25/128], Step [3/3], Loss: 0.0944\n",
            "Epoch [26/128], Step [1/3], Loss: 0.1291\n",
            "Epoch [26/128], Step [2/3], Loss: 0.1118\n",
            "Epoch [26/128], Step [3/3], Loss: 0.1313\n",
            "Epoch [27/128], Step [1/3], Loss: 0.1096\n",
            "Epoch [27/128], Step [2/3], Loss: 0.1287\n",
            "Epoch [27/128], Step [3/3], Loss: 0.0787\n",
            "Epoch [28/128], Step [1/3], Loss: 0.1132\n",
            "Epoch [28/128], Step [2/3], Loss: 0.1040\n",
            "Epoch [28/128], Step [3/3], Loss: 0.0770\n",
            "Epoch [29/128], Step [1/3], Loss: 0.0769\n",
            "Epoch [29/128], Step [2/3], Loss: 0.0524\n",
            "Epoch [29/128], Step [3/3], Loss: 0.1556\n",
            "Epoch [30/128], Step [1/3], Loss: 0.0722\n",
            "Epoch [30/128], Step [2/3], Loss: 0.0920\n",
            "Epoch [30/128], Step [3/3], Loss: 0.1077\n",
            "Epoch [31/128], Step [1/3], Loss: 0.0795\n",
            "Epoch [31/128], Step [2/3], Loss: 0.0507\n",
            "Epoch [31/128], Step [3/3], Loss: 0.0990\n",
            "Epoch [32/128], Step [1/3], Loss: 0.0602\n",
            "Epoch [32/128], Step [2/3], Loss: 0.0641\n",
            "Epoch [32/128], Step [3/3], Loss: 0.0732\n",
            "Epoch [33/128], Step [1/3], Loss: 0.0725\n",
            "Epoch [33/128], Step [2/3], Loss: 0.0416\n",
            "Epoch [33/128], Step [3/3], Loss: 0.0619\n",
            "Epoch [34/128], Step [1/3], Loss: 0.0499\n",
            "Epoch [34/128], Step [2/3], Loss: 0.0419\n",
            "Epoch [34/128], Step [3/3], Loss: 0.0886\n",
            "Epoch [35/128], Step [1/3], Loss: 0.0517\n",
            "Epoch [35/128], Step [2/3], Loss: 0.0409\n",
            "Epoch [35/128], Step [3/3], Loss: 0.0526\n",
            "Epoch [36/128], Step [1/3], Loss: 0.0446\n",
            "Epoch [36/128], Step [2/3], Loss: 0.0390\n",
            "Epoch [36/128], Step [3/3], Loss: 0.0500\n",
            "Epoch [37/128], Step [1/3], Loss: 0.0395\n",
            "Epoch [37/128], Step [2/3], Loss: 0.0379\n",
            "Epoch [37/128], Step [3/3], Loss: 0.0749\n",
            "Epoch [38/128], Step [1/3], Loss: 0.0484\n",
            "Epoch [38/128], Step [2/3], Loss: 0.0362\n",
            "Epoch [38/128], Step [3/3], Loss: 0.0244\n",
            "Epoch [39/128], Step [1/3], Loss: 0.0393\n",
            "Epoch [39/128], Step [2/3], Loss: 0.0370\n",
            "Epoch [39/128], Step [3/3], Loss: 0.0273\n",
            "Epoch [40/128], Step [1/3], Loss: 0.0312\n",
            "Epoch [40/128], Step [2/3], Loss: 0.0484\n",
            "Epoch [40/128], Step [3/3], Loss: 0.0255\n",
            "Epoch [41/128], Step [1/3], Loss: 0.0324\n",
            "Epoch [41/128], Step [2/3], Loss: 0.0257\n",
            "Epoch [41/128], Step [3/3], Loss: 0.0456\n",
            "Epoch [42/128], Step [1/3], Loss: 0.0265\n",
            "Epoch [42/128], Step [2/3], Loss: 0.0365\n",
            "Epoch [42/128], Step [3/3], Loss: 0.0270\n",
            "Epoch [43/128], Step [1/3], Loss: 0.0277\n",
            "Epoch [43/128], Step [2/3], Loss: 0.0204\n",
            "Epoch [43/128], Step [3/3], Loss: 0.0329\n",
            "Epoch [44/128], Step [1/3], Loss: 0.0273\n",
            "Epoch [44/128], Step [2/3], Loss: 0.0209\n",
            "Epoch [44/128], Step [3/3], Loss: 0.0310\n",
            "Epoch [45/128], Step [1/3], Loss: 0.0262\n",
            "Epoch [45/128], Step [2/3], Loss: 0.0192\n",
            "Epoch [45/128], Step [3/3], Loss: 0.0351\n",
            "Epoch [46/128], Step [1/3], Loss: 0.0238\n",
            "Epoch [46/128], Step [2/3], Loss: 0.0218\n",
            "Epoch [46/128], Step [3/3], Loss: 0.0386\n",
            "Epoch [47/128], Step [1/3], Loss: 0.0197\n",
            "Epoch [47/128], Step [2/3], Loss: 0.0317\n",
            "Epoch [47/128], Step [3/3], Loss: 0.0142\n",
            "Epoch [48/128], Step [1/3], Loss: 0.0316\n",
            "Epoch [48/128], Step [2/3], Loss: 0.0147\n",
            "Epoch [48/128], Step [3/3], Loss: 0.0235\n",
            "Epoch [49/128], Step [1/3], Loss: 0.0132\n",
            "Epoch [49/128], Step [2/3], Loss: 0.0190\n",
            "Epoch [49/128], Step [3/3], Loss: 0.0347\n",
            "Epoch [50/128], Step [1/3], Loss: 0.0149\n",
            "Epoch [50/128], Step [2/3], Loss: 0.0192\n",
            "Epoch [50/128], Step [3/3], Loss: 0.0285\n",
            "Epoch [51/128], Step [1/3], Loss: 0.0179\n",
            "Epoch [51/128], Step [2/3], Loss: 0.0126\n",
            "Epoch [51/128], Step [3/3], Loss: 0.0340\n",
            "Epoch [52/128], Step [1/3], Loss: 0.0223\n",
            "Epoch [52/128], Step [2/3], Loss: 0.0157\n",
            "Epoch [52/128], Step [3/3], Loss: 0.0183\n",
            "Epoch [53/128], Step [1/3], Loss: 0.0185\n",
            "Epoch [53/128], Step [2/3], Loss: 0.0169\n",
            "Epoch [53/128], Step [3/3], Loss: 0.0162\n",
            "Epoch [54/128], Step [1/3], Loss: 0.0205\n",
            "Epoch [54/128], Step [2/3], Loss: 0.0119\n",
            "Epoch [54/128], Step [3/3], Loss: 0.0160\n",
            "Epoch [55/128], Step [1/3], Loss: 0.0119\n",
            "Epoch [55/128], Step [2/3], Loss: 0.0222\n",
            "Epoch [55/128], Step [3/3], Loss: 0.0257\n",
            "Epoch [56/128], Step [1/3], Loss: 0.0154\n",
            "Epoch [56/128], Step [2/3], Loss: 0.0165\n",
            "Epoch [56/128], Step [3/3], Loss: 0.0160\n",
            "Epoch [57/128], Step [1/3], Loss: 0.0121\n",
            "Epoch [57/128], Step [2/3], Loss: 0.0129\n",
            "Epoch [57/128], Step [3/3], Loss: 0.0263\n",
            "Epoch [58/128], Step [1/3], Loss: 0.0177\n",
            "Epoch [58/128], Step [2/3], Loss: 0.0131\n",
            "Epoch [58/128], Step [3/3], Loss: 0.0200\n",
            "Epoch [59/128], Step [1/3], Loss: 0.0142\n",
            "Epoch [59/128], Step [2/3], Loss: 0.0109\n",
            "Epoch [59/128], Step [3/3], Loss: 0.0185\n",
            "Epoch [60/128], Step [1/3], Loss: 0.0162\n",
            "Epoch [60/128], Step [2/3], Loss: 0.0137\n",
            "Epoch [60/128], Step [3/3], Loss: 0.0109\n",
            "Epoch [61/128], Step [1/3], Loss: 0.0143\n",
            "Epoch [61/128], Step [2/3], Loss: 0.0141\n",
            "Epoch [61/128], Step [3/3], Loss: 0.0118\n",
            "Epoch [62/128], Step [1/3], Loss: 0.0130\n",
            "Epoch [62/128], Step [2/3], Loss: 0.0123\n",
            "Epoch [62/128], Step [3/3], Loss: 0.0243\n",
            "Epoch [63/128], Step [1/3], Loss: 0.0074\n",
            "Epoch [63/128], Step [2/3], Loss: 0.0239\n",
            "Epoch [63/128], Step [3/3], Loss: 0.0127\n",
            "Epoch [64/128], Step [1/3], Loss: 0.0099\n",
            "Epoch [64/128], Step [2/3], Loss: 0.0142\n",
            "Epoch [64/128], Step [3/3], Loss: 0.0126\n",
            "Epoch [65/128], Step [1/3], Loss: 0.0109\n",
            "Epoch [65/128], Step [2/3], Loss: 0.0094\n",
            "Epoch [65/128], Step [3/3], Loss: 0.0177\n",
            "Epoch [66/128], Step [1/3], Loss: 0.0103\n",
            "Epoch [66/128], Step [2/3], Loss: 0.0136\n",
            "Epoch [66/128], Step [3/3], Loss: 0.0138\n",
            "Epoch [67/128], Step [1/3], Loss: 0.0057\n",
            "Epoch [67/128], Step [2/3], Loss: 0.0194\n",
            "Epoch [67/128], Step [3/3], Loss: 0.0187\n",
            "Epoch [68/128], Step [1/3], Loss: 0.0102\n",
            "Epoch [68/128], Step [2/3], Loss: 0.0098\n",
            "Epoch [68/128], Step [3/3], Loss: 0.0255\n",
            "Epoch [69/128], Step [1/3], Loss: 0.0063\n",
            "Epoch [69/128], Step [2/3], Loss: 0.0089\n",
            "Epoch [69/128], Step [3/3], Loss: 0.0339\n",
            "Epoch [70/128], Step [1/3], Loss: 0.0139\n",
            "Epoch [70/128], Step [2/3], Loss: 0.0070\n",
            "Epoch [70/128], Step [3/3], Loss: 0.0136\n",
            "Epoch [71/128], Step [1/3], Loss: 0.0134\n",
            "Epoch [71/128], Step [2/3], Loss: 0.0103\n",
            "Epoch [71/128], Step [3/3], Loss: 0.0091\n",
            "Epoch [72/128], Step [1/3], Loss: 0.0110\n",
            "Epoch [72/128], Step [2/3], Loss: 0.0100\n",
            "Epoch [72/128], Step [3/3], Loss: 0.0100\n",
            "Epoch [73/128], Step [1/3], Loss: 0.0081\n",
            "Epoch [73/128], Step [2/3], Loss: 0.0135\n",
            "Epoch [73/128], Step [3/3], Loss: 0.0069\n",
            "Epoch [74/128], Step [1/3], Loss: 0.0053\n",
            "Epoch [74/128], Step [2/3], Loss: 0.0123\n",
            "Epoch [74/128], Step [3/3], Loss: 0.0131\n",
            "Epoch [75/128], Step [1/3], Loss: 0.0109\n",
            "Epoch [75/128], Step [2/3], Loss: 0.0076\n",
            "Epoch [75/128], Step [3/3], Loss: 0.0109\n",
            "Epoch [76/128], Step [1/3], Loss: 0.0071\n",
            "Epoch [76/128], Step [2/3], Loss: 0.0097\n",
            "Epoch [76/128], Step [3/3], Loss: 0.0136\n",
            "Epoch [77/128], Step [1/3], Loss: 0.0103\n",
            "Epoch [77/128], Step [2/3], Loss: 0.0091\n",
            "Epoch [77/128], Step [3/3], Loss: 0.0116\n",
            "Epoch [78/128], Step [1/3], Loss: 0.0068\n",
            "Epoch [78/128], Step [2/3], Loss: 0.0075\n",
            "Epoch [78/128], Step [3/3], Loss: 0.0158\n",
            "Epoch [79/128], Step [1/3], Loss: 0.0089\n",
            "Epoch [79/128], Step [2/3], Loss: 0.0096\n",
            "Epoch [79/128], Step [3/3], Loss: 0.0047\n",
            "Epoch [80/128], Step [1/3], Loss: 0.0069\n",
            "Epoch [80/128], Step [2/3], Loss: 0.0062\n",
            "Epoch [80/128], Step [3/3], Loss: 0.0155\n",
            "Epoch [81/128], Step [1/3], Loss: 0.0080\n",
            "Epoch [81/128], Step [2/3], Loss: 0.0088\n",
            "Epoch [81/128], Step [3/3], Loss: 0.0069\n",
            "Epoch [82/128], Step [1/3], Loss: 0.0064\n",
            "Epoch [82/128], Step [2/3], Loss: 0.0102\n",
            "Epoch [82/128], Step [3/3], Loss: 0.0094\n",
            "Epoch [83/128], Step [1/3], Loss: 0.0046\n",
            "Epoch [83/128], Step [2/3], Loss: 0.0131\n",
            "Epoch [83/128], Step [3/3], Loss: 0.0068\n",
            "Epoch [84/128], Step [1/3], Loss: 0.0051\n",
            "Epoch [84/128], Step [2/3], Loss: 0.0066\n",
            "Epoch [84/128], Step [3/3], Loss: 0.0177\n",
            "Epoch [85/128], Step [1/3], Loss: 0.0077\n",
            "Epoch [85/128], Step [2/3], Loss: 0.0083\n",
            "Epoch [85/128], Step [3/3], Loss: 0.0060\n",
            "Epoch [86/128], Step [1/3], Loss: 0.0075\n",
            "Epoch [86/128], Step [2/3], Loss: 0.0068\n",
            "Epoch [86/128], Step [3/3], Loss: 0.0089\n",
            "Epoch [87/128], Step [1/3], Loss: 0.0095\n",
            "Epoch [87/128], Step [2/3], Loss: 0.0054\n",
            "Epoch [87/128], Step [3/3], Loss: 0.0060\n",
            "Epoch [88/128], Step [1/3], Loss: 0.0066\n",
            "Epoch [88/128], Step [2/3], Loss: 0.0066\n",
            "Epoch [88/128], Step [3/3], Loss: 0.0076\n",
            "Epoch [89/128], Step [1/3], Loss: 0.0060\n",
            "Epoch [89/128], Step [2/3], Loss: 0.0075\n",
            "Epoch [89/128], Step [3/3], Loss: 0.0065\n",
            "Epoch [90/128], Step [1/3], Loss: 0.0097\n",
            "Epoch [90/128], Step [2/3], Loss: 0.0041\n",
            "Epoch [90/128], Step [3/3], Loss: 0.0109\n",
            "Epoch [91/128], Step [1/3], Loss: 0.0094\n",
            "Epoch [91/128], Step [2/3], Loss: 0.0071\n",
            "Epoch [91/128], Step [3/3], Loss: 0.0051\n",
            "Epoch [92/128], Step [1/3], Loss: 0.0069\n",
            "Epoch [92/128], Step [2/3], Loss: 0.0065\n",
            "Epoch [92/128], Step [3/3], Loss: 0.0050\n",
            "Epoch [93/128], Step [1/3], Loss: 0.0063\n",
            "Epoch [93/128], Step [2/3], Loss: 0.0065\n",
            "Epoch [93/128], Step [3/3], Loss: 0.0107\n",
            "Epoch [94/128], Step [1/3], Loss: 0.0061\n",
            "Epoch [94/128], Step [2/3], Loss: 0.0085\n",
            "Epoch [94/128], Step [3/3], Loss: 0.0029\n",
            "Epoch [95/128], Step [1/3], Loss: 0.0061\n",
            "Epoch [95/128], Step [2/3], Loss: 0.0072\n",
            "Epoch [95/128], Step [3/3], Loss: 0.0052\n",
            "Epoch [96/128], Step [1/3], Loss: 0.0040\n",
            "Epoch [96/128], Step [2/3], Loss: 0.0085\n",
            "Epoch [96/128], Step [3/3], Loss: 0.0094\n",
            "Epoch [97/128], Step [1/3], Loss: 0.0088\n",
            "Epoch [97/128], Step [2/3], Loss: 0.0041\n",
            "Epoch [97/128], Step [3/3], Loss: 0.0050\n",
            "Epoch [98/128], Step [1/3], Loss: 0.0062\n",
            "Epoch [98/128], Step [2/3], Loss: 0.0066\n",
            "Epoch [98/128], Step [3/3], Loss: 0.0047\n",
            "Epoch [99/128], Step [1/3], Loss: 0.0044\n",
            "Epoch [99/128], Step [2/3], Loss: 0.0048\n",
            "Epoch [99/128], Step [3/3], Loss: 0.0122\n",
            "Epoch [100/128], Step [1/3], Loss: 0.0057\n",
            "Epoch [100/128], Step [2/3], Loss: 0.0065\n",
            "Epoch [100/128], Step [3/3], Loss: 0.0040\n",
            "Epoch [101/128], Step [1/3], Loss: 0.0068\n",
            "Epoch [101/128], Step [2/3], Loss: 0.0036\n",
            "Epoch [101/128], Step [3/3], Loss: 0.0095\n",
            "Epoch [102/128], Step [1/3], Loss: 0.0040\n",
            "Epoch [102/128], Step [2/3], Loss: 0.0052\n",
            "Epoch [102/128], Step [3/3], Loss: 0.0097\n",
            "Epoch [103/128], Step [1/3], Loss: 0.0029\n",
            "Epoch [103/128], Step [2/3], Loss: 0.0078\n",
            "Epoch [103/128], Step [3/3], Loss: 0.0068\n",
            "Epoch [104/128], Step [1/3], Loss: 0.0034\n",
            "Epoch [104/128], Step [2/3], Loss: 0.0063\n",
            "Epoch [104/128], Step [3/3], Loss: 0.0065\n",
            "Epoch [105/128], Step [1/3], Loss: 0.0060\n",
            "Epoch [105/128], Step [2/3], Loss: 0.0032\n",
            "Epoch [105/128], Step [3/3], Loss: 0.0081\n",
            "Epoch [106/128], Step [1/3], Loss: 0.0061\n",
            "Epoch [106/128], Step [2/3], Loss: 0.0060\n",
            "Epoch [106/128], Step [3/3], Loss: 0.0031\n",
            "Epoch [107/128], Step [1/3], Loss: 0.0034\n",
            "Epoch [107/128], Step [2/3], Loss: 0.0059\n",
            "Epoch [107/128], Step [3/3], Loss: 0.0074\n",
            "Epoch [108/128], Step [1/3], Loss: 0.0064\n",
            "Epoch [108/128], Step [2/3], Loss: 0.0047\n",
            "Epoch [108/128], Step [3/3], Loss: 0.0053\n",
            "Epoch [109/128], Step [1/3], Loss: 0.0049\n",
            "Epoch [109/128], Step [2/3], Loss: 0.0053\n",
            "Epoch [109/128], Step [3/3], Loss: 0.0084\n",
            "Epoch [110/128], Step [1/3], Loss: 0.0062\n",
            "Epoch [110/128], Step [2/3], Loss: 0.0041\n",
            "Epoch [110/128], Step [3/3], Loss: 0.0092\n",
            "Epoch [111/128], Step [1/3], Loss: 0.0039\n",
            "Epoch [111/128], Step [2/3], Loss: 0.0050\n",
            "Epoch [111/128], Step [3/3], Loss: 0.0089\n",
            "Epoch [112/128], Step [1/3], Loss: 0.0032\n",
            "Epoch [112/128], Step [2/3], Loss: 0.0099\n",
            "Epoch [112/128], Step [3/3], Loss: 0.0021\n",
            "Epoch [113/128], Step [1/3], Loss: 0.0036\n",
            "Epoch [113/128], Step [2/3], Loss: 0.0059\n",
            "Epoch [113/128], Step [3/3], Loss: 0.0047\n",
            "Epoch [114/128], Step [1/3], Loss: 0.0034\n",
            "Epoch [114/128], Step [2/3], Loss: 0.0063\n",
            "Epoch [114/128], Step [3/3], Loss: 0.0052\n",
            "Epoch [115/128], Step [1/3], Loss: 0.0047\n",
            "Epoch [115/128], Step [2/3], Loss: 0.0024\n",
            "Epoch [115/128], Step [3/3], Loss: 0.0169\n",
            "Epoch [116/128], Step [1/3], Loss: 0.0064\n",
            "Epoch [116/128], Step [2/3], Loss: 0.0031\n",
            "Epoch [116/128], Step [3/3], Loss: 0.0045\n",
            "Epoch [117/128], Step [1/3], Loss: 0.0065\n",
            "Epoch [117/128], Step [2/3], Loss: 0.0061\n",
            "Epoch [117/128], Step [3/3], Loss: 0.0048\n",
            "Epoch [118/128], Step [1/3], Loss: 0.0029\n",
            "Epoch [118/128], Step [2/3], Loss: 0.0062\n",
            "Epoch [118/128], Step [3/3], Loss: 0.0065\n",
            "Epoch [119/128], Step [1/3], Loss: 0.0048\n",
            "Epoch [119/128], Step [2/3], Loss: 0.0035\n",
            "Epoch [119/128], Step [3/3], Loss: 0.0056\n",
            "Epoch [120/128], Step [1/3], Loss: 0.0032\n",
            "Epoch [120/128], Step [2/3], Loss: 0.0044\n",
            "Epoch [120/128], Step [3/3], Loss: 0.0085\n",
            "Epoch [121/128], Step [1/3], Loss: 0.0055\n",
            "Epoch [121/128], Step [2/3], Loss: 0.0034\n",
            "Epoch [121/128], Step [3/3], Loss: 0.0034\n",
            "Epoch [122/128], Step [1/3], Loss: 0.0047\n",
            "Epoch [122/128], Step [2/3], Loss: 0.0035\n",
            "Epoch [122/128], Step [3/3], Loss: 0.0039\n",
            "Epoch [123/128], Step [1/3], Loss: 0.0043\n",
            "Epoch [123/128], Step [2/3], Loss: 0.0030\n",
            "Epoch [123/128], Step [3/3], Loss: 0.0060\n",
            "Epoch [124/128], Step [1/3], Loss: 0.0064\n",
            "Epoch [124/128], Step [2/3], Loss: 0.0027\n",
            "Epoch [124/128], Step [3/3], Loss: 0.0036\n",
            "Epoch [125/128], Step [1/3], Loss: 0.0037\n",
            "Epoch [125/128], Step [2/3], Loss: 0.0037\n",
            "Epoch [125/128], Step [3/3], Loss: 0.0040\n",
            "Epoch [126/128], Step [1/3], Loss: 0.0081\n",
            "Epoch [126/128], Step [2/3], Loss: 0.0024\n",
            "Epoch [126/128], Step [3/3], Loss: 0.0045\n",
            "Epoch [127/128], Step [1/3], Loss: 0.0038\n",
            "Epoch [127/128], Step [2/3], Loss: 0.0041\n",
            "Epoch [127/128], Step [3/3], Loss: 0.0043\n",
            "Epoch [128/128], Step [1/3], Loss: 0.0020\n",
            "Epoch [128/128], Step [2/3], Loss: 0.0046\n",
            "Epoch [128/128], Step [3/3], Loss: 0.0073\n",
            "Accuracy of the model on the test data: 100.00%\n",
            "Predicted class: Bold Text, True class: Bold Text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python predict.py --image ../../datasets/images/13d079ae-be5c-49a3-bf99-39a259514968.png --caption \"ICON\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwuP2Kn-_Swa",
        "outputId": "5b18c4d6-a5d4-4590-9beb-8cc858883e65"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: Back Arrow Icon Button\n"
          ]
        }
      ]
    }
  ]
}